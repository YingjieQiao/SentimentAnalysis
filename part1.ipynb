{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/yingjieqiao/Desktop/term6/mlproj', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python38.zip', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8', '/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/lib-dynload', '', '/Users/yingjieqiao/Desktop/term6/mlproj/venv/lib/python3.8/site-packages', '/Users/yingjieqiao/Desktop/term6/mlproj/venv/lib/python3.8/site-packages/IPython/extensions', '/Users/yingjieqiao/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_TRAINING_DATA = \"./ES/train\"\n",
    "ES_TESTING_DATA = \"./ES/dev.in\"\n",
    "ES_LABELED_DATA = \"./ES/dev.out\"\n",
    "\n",
    "RU_TRAINING_DATA = \"./RU/train\"\n",
    "RU_TESTING_DATA = \"./RU/dev.in\"\n",
    "RU_LABELED_DATA = \"./RU/dev.out\"\n",
    "\n",
    "def readTrainingData(filePath):\n",
    "    data = []\n",
    "    with open(filePath) as file:\n",
    "        data = file.read().splitlines()\n",
    "    \n",
    "    output = []\n",
    "    for line in data:\n",
    "        line = line.split(\" \")\n",
    "        if(len(line) > 2):\n",
    "            # . â€¦ O\n",
    "            line = [\" \".join(line[0:len(line)-1]), line[len(line)-1]]\n",
    "            output.append(line)\n",
    "        else:\n",
    "            output.append(line)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def readTestData(filePath):\n",
    "    data = []\n",
    "    with open(filePath) as file:\n",
    "        data = file.read().splitlines()\n",
    "    \n",
    "    output = []\n",
    "    for line in data:\n",
    "        output.append(line)\n",
    "    \n",
    "    return output\n",
    "\n",
    "es_training_data = readTrainingData(ES_TRAINING_DATA)\n",
    "ru_training_data = readTrainingData(RU_TRAINING_DATA)\n",
    "es_testing_data = readTestData(ES_TESTING_DATA)\n",
    "ru_testing_data = readTestData(RU_TESTING_DATA)\n",
    "es_labeled_data = readTrainingData(ES_LABELED_DATA)\n",
    "ru_labeled_data = readTrainingData(RU_LABELED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write a function that estimates the emission parameters from the training set using MLE (maximum\n",
    "likelihood estimation)\n",
    "\n",
    "One problem with estimating the emission parameters is that some words that appear in the test set\n",
    "do not appear in the training set. One simple idea to handle this issue is as follows. We introduce\n",
    "a special word token #UNK#, and make the following modifications to the computation of emission\n",
    "probabilitie\n",
    "\"\"\"\n",
    "\n",
    "def emissionMLE(dataset, k=1):\n",
    "    observations = {} \n",
    "    tags = {} # tag/state\n",
    "    tagToObs = {}\n",
    "\n",
    "    for data in dataset:\n",
    "        if len(data) < 2:\n",
    "            continue\n",
    "        o = data[0]\n",
    "        t = data[1]\n",
    "\n",
    "        if o not in observations:\n",
    "            observations[o] = 0\n",
    "        observations[o] += 1\n",
    "\n",
    "        if t not in tags:\n",
    "            tags[t] = 0\n",
    "        tags[t] += 1\n",
    "\n",
    "        key = (t, o)\n",
    "        if key not in tagToObs:\n",
    "            tagToObs[key] = 0\n",
    "        tagToObs[key] += 1\n",
    "\n",
    "    res = {}\n",
    "    for key in tagToObs.keys():\n",
    "        res[key] = tagToObs[key] / (tags[key[0]] + k)\n",
    "    for key in tags.keys():\n",
    "        unk_key = (key, \"#UNK#\")\n",
    "        res[unk_key] = k / (tags[key] + k)\n",
    "    \n",
    "    return res\n",
    "\n",
    "es_emission = emissionMLE(dataset=es_training_data, k=1)\n",
    "ru_emission = emissionMLE(dataset=ru_training_data, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5560\n",
      "2\n",
      "5266\n",
      "2\n",
      "5560\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Implement a simple sentiment analysis system that produces the tag for each word x in the sequence\n",
    "\"\"\"\n",
    "\n",
    "def argmax(emission):\n",
    "    map = {}\n",
    "    res = {}\n",
    "    for key, value in emission.items():\n",
    "        t = key[0]\n",
    "        o = key[1]\n",
    "\n",
    "        if o not in map:\n",
    "            map[o] = value\n",
    "            res[o] = t\n",
    "        else:\n",
    "            if value > map[o]:\n",
    "                map[o] = value\n",
    "                res[o] = t\n",
    "\n",
    "    return res\n",
    "\n",
    "es_seqmap = argmax(es_emission)\n",
    "ru_seqmap = argmax(ru_emission)\n",
    "\n",
    "ES_PRED = \"./ES/dev_pred.out\"\n",
    "RU_PRED = \"./RU/dev_pred.out\"\n",
    "\n",
    "def serializeSeqmap(seqmap, testData):\n",
    "    serializedSeqmap = []\n",
    "    for data in testData:\n",
    "        if data is None or len(data) == 0:\n",
    "            continue\n",
    "        entry = [data]\n",
    "        if data not in seqmap:\n",
    "            entry.append(\"#UNK#\")\n",
    "        else:\n",
    "            entry.append(seqmap[data])\n",
    "        serializedSeqmap.append(entry)\n",
    "\n",
    "    return serializedSeqmap\n",
    "    \n",
    "es_seialized_seqmap = serializeSeqmap(es_seqmap, es_testing_data)\n",
    "\n",
    "# print(len(es_testing_data))\n",
    "# print(len(es_testing_data[0]))\n",
    "# print(len(es_seialized_seqmap))\n",
    "# print(len(es_seialized_seqmap[0]))\n",
    "# print(len(es_labeled_data))\n",
    "# print(len(es_labeled_data[0]))\n",
    "\n",
    "\n",
    "def calculateScore(serializedSeqmap, labeledData):\n",
    "    \n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e485bb5d8f1d8ef2575d7ba8353c73a1ec82aa3e63a21c343a17a733c833a62e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
